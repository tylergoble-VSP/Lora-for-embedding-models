{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analytics and Performance Tracking\n",
        "\n",
        "This notebook analyzes performance metrics, training logs, and GPU utilization from the LoRA fine-tuning workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries for analytics\n",
        "import pandas as pd  # Pandas for data manipulation\n",
        "import matplotlib.pyplot as plt  # Matplotlib for plotting\n",
        "from pathlib import Path  # Path handling\n",
        "import glob  # For finding log files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Timing Logs\n",
        "\n",
        "Load timing logs generated throughout repository execution. These logs track function execution times and help identify bottlenecks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all timing log files\n",
        "log_files = glob.glob(\"outputs/logs/timing_*.csv\")\n",
        "\n",
        "if log_files:\n",
        "    # Load the most recent log file\n",
        "    latest_log = max(log_files, key=Path)\n",
        "    print(f\"Loading timing log: {latest_log}\")\n",
        "    \n",
        "    # Load timing logs\n",
        "    logs = pd.read_csv(latest_log, names=[\"function_name\", \"duration\", \"timestamp\"])\n",
        "    \n",
        "    print(f\"\\nLoaded {len(logs)} timing records\")\n",
        "    print(\"\\nSample records:\")\n",
        "    print(logs.head())\n",
        "else:\n",
        "    print(\"No timing logs found. Run training or other timed operations first.\")\n",
        "    logs = pd.DataFrame(columns=[\"function_name\", \"duration\", \"timestamp\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function Execution Duration Over Time\n",
        "\n",
        "Plot runtime trends across execution sessions to visualize improvement or degradation over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(logs) > 0:\n",
        "    # Convert timestamp to datetime for better plotting\n",
        "    logs[\"datetime\"] = pd.to_datetime(logs[\"timestamp\"], unit=\"s\")\n",
        "    \n",
        "    # Plot execution duration over time\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(logs[\"datetime\"], logs[\"duration\"], marker=\"o\", alpha=0.7)\n",
        "    plt.xlabel(\"Timestamp\")\n",
        "    plt.ylabel(\"Duration (seconds)\")\n",
        "    plt.title(\"Function Execution Duration Over Time\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Total execution time: {logs['duration'].sum():.2f} seconds\")\n",
        "    print(f\"Average execution time: {logs['duration'].mean():.2f} seconds\")\n",
        "    print(f\"Longest execution: {logs['duration'].max():.2f} seconds ({logs.loc[logs['duration'].idxmax(), 'function_name']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function Performance Breakdown\n",
        "\n",
        "Analyze which functions take the most time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(logs) > 0:\n",
        "    # Group by function name and compute statistics\n",
        "    function_stats = logs.groupby(\"function_name\")[\"duration\"].agg([\n",
        "        \"count\", \"mean\", \"sum\", \"min\", \"max\"\n",
        "    ]).round(3)\n",
        "    function_stats.columns = [\"Call Count\", \"Avg Duration (s)\", \"Total Duration (s)\", \"Min (s)\", \"Max (s)\"]\n",
        "    function_stats = function_stats.sort_values(\"Total Duration (s)\", ascending=False)\n",
        "    \n",
        "    print(\"Function Performance Statistics:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(function_stats)\n",
        "    \n",
        "    # Plot total duration by function\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    function_stats[\"Total Duration (s)\"].plot(kind=\"barh\")\n",
        "    plt.xlabel(\"Total Duration (seconds)\")\n",
        "    plt.ylabel(\"Function Name\")\n",
        "    plt.title(\"Total Execution Time by Function\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU Utilization (if available)\n",
        "\n",
        "Check GPU usage during training. This helps identify if the GPU is being fully utilized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability and utilization\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Information:\")\n",
        "    print(\"-\" * 40)\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"  Memory Allocated: {torch.cuda.memory_allocated(i) / 1e9:.2f} GB\")\n",
        "        print(f\"  Memory Reserved: {torch.cuda.memory_reserved(i) / 1e9:.2f} GB\")\n",
        "        print(f\"  Total Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"CUDA not available - using CPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loss Convergence (if available)\n",
        "\n",
        "If training loss logs are available, visualize loss convergence over epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look for training loss files (if saved separately)\n",
        "# In practice, you might save loss values to a CSV during training\n",
        "loss_files = glob.glob(\"outputs/logs/losses_*.csv\")\n",
        "\n",
        "if loss_files:\n",
        "    latest_loss = max(loss_files, key=Path)\n",
        "    loss_data = pd.read_csv(latest_loss)\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(loss_data[\"epoch\"], loss_data[\"loss\"], marker=\"o\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Training Loss\")\n",
        "    plt.title(\"Training Loss Convergence\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Initial loss: {loss_data['loss'].iloc[0]:.4f}\")\n",
        "    print(f\"Final loss: {loss_data['loss'].iloc[-1]:.4f}\")\n",
        "    print(f\"Improvement: {((loss_data['loss'].iloc[0] - loss_data['loss'].iloc[-1]) / loss_data['loss'].iloc[0] * 100):.1f}%\")\n",
        "else:\n",
        "    print(\"No training loss logs found. Losses are printed during training in notebook 05.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
